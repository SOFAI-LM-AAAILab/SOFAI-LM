{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# \ud83d\udc1b SOFAI-Core: Code Debugging Domain\n",
                "\n",
                "## Automated Bug Fixing with DebugBench & LeetCode Validation\n",
                "\n",
                "In this notebook, you will learn:\n",
                "\n",
                "1. **What is the Code Debugging Domain?** - Problem definition and components\n",
                "2. **The DebugBench Dataset** - 17 bug types, 4,253+ instances\n",
                "3. **Setting Up LeetCode Validation** - Step-by-step session cookie setup\n",
                "4. **Domain Architecture** - All components explained\n",
                "5. **Running the Full Pipeline** - End-to-end debugging with SOFAI\n",
                "\n",
                "---\n",
                "\n",
                "### \u26a0\ufe0f Important Prerequisites\n",
                "\n",
                "This domain requires:\n",
                "1. **DebugBench Dataset** - Already included in `domains/code_debugging/data/`\n",
                "2. **LeetCode Account** - For real code validation\n",
                "3. **LEETCODE_SESSION Cookie** - See setup instructions below\n",
                "4. **Ollama** - For LLM inference (optional for component demos)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================\n",
                "# COLAB SETUP - Run this cell first if using Google Colab\n",
                "# ============================================================\n",
                "import subprocess\n",
                "import sys\n",
                "import os\n",
                "\n",
                "# Check if running in Colab\n",
                "IN_COLAB = 'google.colab' in sys.modules\n",
                "\n",
                "if IN_COLAB:\n",
                "    print(\"\ufffd\ufffd Running in Google Colab - Setting up environment...\")\n",
                "    \n",
                "    # Clone the repository\n",
                "    if not os.path.exists('SOFAI-LM'):\n",
                "        !git clone https://github.com/YOUR_USERNAME/SOFAI-LM.git\n",
                "    %cd SOFAI-LM\n",
                "    \n",
                "    # Install dependencies\n",
                "    !pip install -q -r requirements.txt\n",
                "    \n",
                "    # Install Ollama for Colab\n",
                "    !curl -fsSL https://ollama.com/install.sh | sh\n",
                "    \n",
                "    # Start Ollama server in background\n",
                "    import subprocess\n",
                "    subprocess.Popen(['ollama', 'serve'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
                "    import time\n",
                "    time.sleep(3)  # Wait for server to start\n",
                "    \n",
                "    print(\"\u2705 Colab setup complete!\")\n",
                "else:\n",
                "    print(\"Running locally - no Colab setup needed.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Part 1: Understanding the Code Debugging Domain\n",
                "\n",
                "### What is Code Debugging?\n",
                "\n",
                "**Code Debugging** is the process of identifying and fixing errors (bugs) in source code. In the SOFAI framework, this is treated as a Constraint Satisfaction Problem where:\n",
                "\n",
                "- **Problem**: A buggy code snippet with a known problem description\n",
                "- **Solution**: Fixed code that passes all test cases\n",
                "- **Constraint**: The fixed code must be semantically equivalent to the intended solution\n",
                "\n",
                "### The Challenge\n",
                "\n",
                "Unlike graph coloring where validation is deterministic, code debugging requires:\n",
                "- **Semantic understanding** of what the code should do\n",
                "- **Syntax correctness** (no compile errors)\n",
                "- **Passing all test cases** (often hidden)\n",
                "\n",
                "### SOFAI's Approach\n",
                "\n",
                "```\n",
                "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
                "\u2502                     Code Debugging Flow                         \u2502\n",
                "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
                "\u2502                                                                 \u2502\n",
                "\u2502  1. DEBUGBENCH        2. PROMPT             3. LLM              \u2502\n",
                "\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500      \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500             \u2500\u2500\u2500\u2500\u2500                \u2502\n",
                "\u2502  Load buggy code  \u2192   IO_INTENTION   \u2192    Generate             \u2502\n",
                "\u2502  + description        format prompt        fixed code           \u2502\n",
                "\u2502                                                                 \u2502\n",
                "\u2502       \u2193                                                         \u2502\n",
                "\u2502                                                                 \u2502\n",
                "\u2502  4. PARSER            5. LEETCODE API      6. FEEDBACK          \u2502\n",
                "\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500           \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500        \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500          \u2502\n",
                "\u2502  Extract code    \u2192    Submit &        \u2192   Pass: Done!          \u2502\n",
                "\u2502  from <code>tags      run tests           Fail: Retry          \u2502\n",
                "\u2502                                                                 \u2502\n",
                "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup: Add project root to path\n",
                "import sys\n",
                "import os\n",
                "\n",
                "project_root = os.path.dirname(os.getcwd()) if 'notebooks' in os.getcwd() else os.getcwd()\n",
                "if project_root not in sys.path:\n",
                "    sys.path.insert(0, project_root)\n",
                "\n",
                "print(f\"Project root: {project_root}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Part 2: The DebugBench Dataset\n",
                "\n",
                "### What is DebugBench?\n",
                "\n",
                "[DebugBench](https://github.com/thunlp/DebugBench) is a benchmark dataset for code debugging containing:\n",
                "- **4,253 Python3 buggy code instances**\n",
                "- **17 distinct bug types**\n",
                "- Problems sourced from LeetCode\n",
                "- Oracle (correct) solutions for reference\n",
                "\n",
                "### The 17 Bug Types\n",
                "\n",
                "| Category | Bug Types |\n",
                "|----------|----------|\n",
                "| **Logic Errors** | condition error, operation error, variable error |\n",
                "| **Syntax Errors** | missing colons, illegal indentation, unclosed parentheses, unclosed string |\n",
                "| **Reference Errors** | undefined methods, undefined objects, faulty indexing |\n",
                "| **Semantic Errors** | misused == or =, illegal keywords, illegal comment |\n",
                "| **Multiple Bugs** | double (2 bugs), triple (3 bugs), quadruple (4 bugs), other error |\n",
                "\n",
                "### Dataset Location\n",
                "\n",
                "The dataset is pre-loaded in:\n",
                "```\n",
                "domains/code_debugging/data/\n",
                "\u251c\u2500\u2500 python3_condition error.json\n",
                "\u251c\u2500\u2500 python3_double.json\n",
                "\u251c\u2500\u2500 python3_faulty indexing.json\n",
                "\u251c\u2500\u2500 python3_illegal comment.json\n",
                "\u251c\u2500\u2500 python3_illegal indentation.json\n",
                "\u251c\u2500\u2500 python3_illegal keywords.json\n",
                "\u251c\u2500\u2500 python3_missing colons.json\n",
                "\u251c\u2500\u2500 python3_misused == or =.json\n",
                "\u251c\u2500\u2500 python3_operation error.json\n",
                "\u251c\u2500\u2500 python3_other error.json\n",
                "\u251c\u2500\u2500 python3_quadruple.json\n",
                "\u251c\u2500\u2500 python3_triple.json\n",
                "\u251c\u2500\u2500 python3_unclosed parentheses.json\n",
                "\u251c\u2500\u2500 python3_unclosed string.json\n",
                "\u251c\u2500\u2500 python3_undefined methods.json\n",
                "\u251c\u2500\u2500 python3_undefined objects.json\n",
                "\u2514\u2500\u2500 python3_variable error.json\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Explore the bug types and dataset size\n",
                "from domains.code_debugging.data_loader import BUG_TYPES, get_problem_count, DEBUGBENCH_PATH\n",
                "\n",
                "print(\"\ud83d\udcca DebugBench Dataset Overview\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"\\nDataset location: {DEBUGBENCH_PATH}\")\n",
                "print(f\"\\nAvailable bug types ({len(BUG_TYPES)} total):\")\n",
                "print(\"-\" * 60)\n",
                "\n",
                "total_problems = 0\n",
                "for bug_type in BUG_TYPES:\n",
                "    count = get_problem_count(bug_type=bug_type)\n",
                "    total_problems += count\n",
                "    print(f\"  \u2022 {bug_type:25s} : {count:4d} problems\")\n",
                "\n",
                "print(\"-\" * 60)\n",
                "print(f\"  {'TOTAL':25s} : {total_problems:4d} problems\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load and examine a sample problem\n",
                "from domains.code_debugging.data_loader import load_problem_from_dataset\n",
                "\n",
                "print(\"\ud83d\udcdd Sample Problem (condition error)\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "# Load a specific bug type\n",
                "problem = load_problem_from_dataset(language=\"Python3\", bug_type=\"condition error\", problem_index=0)\n",
                "\n",
                "print(f\"\\n\ud83d\udd16 Problem: {problem.slug}\")\n",
                "print(f\"\ud83d\udcca Level: {problem.level}\")\n",
                "print(f\"\ud83d\udc1b Bug Type: {problem.bug_type}\")\n",
                "print(f\"\\n\ud83d\udccb Description:\")\n",
                "print(problem.description[:500] + \"...\" if len(problem.description) > 500 else problem.description)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Show the buggy code\n",
                "print(\"\\n\ud83d\udc1b Buggy Code:\")\n",
                "print(\"-\" * 60)\n",
                "print(problem.buggy_code)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Show the oracle (correct) code for comparison\n",
                "print(\"\\n\u2705 Oracle (Correct) Code:\")\n",
                "print(\"-\" * 60)\n",
                "print(problem.oracle_code)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# The CodeDebuggingProblem dataclass\n",
                "print(\"\\n\ud83d\udce6 CodeDebuggingProblem Structure\")\n",
                "print(\"=\" * 60)\n",
                "print(\"\"\"\n",
                "@dataclass\n",
                "class CodeDebuggingProblem:\n",
                "    slug: str          # LeetCode problem ID (e.g., 'two-sum')\n",
                "    description: str   # Problem statement\n",
                "    examples: List[str] # Input/output examples\n",
                "    constraints: str    # Problem constraints\n",
                "    level: str         # 'easy', 'medium', 'hard'\n",
                "    buggy_code: str    # The code to fix\n",
                "    oracle_code: str   # Reference correct solution\n",
                "    explanations: str  # Bug explanation\n",
                "    content: str       # Full problem content\n",
                "    bug_type: str      # One of the 17 bug types\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Part 3: Setting Up LeetCode Validation \ud83d\udd10\n",
                "\n",
                "The Code Debugging domain uses **real LeetCode submission** to validate solutions. This ensures the fixed code actually works!\n",
                "\n",
                "### Why LeetCode Validation?\n",
                "\n",
                "- \u2705 Real test cases (including hidden ones)\n",
                "- \u2705 Accurate feedback (runtime errors, wrong answers)\n",
                "- \u2705 Performance metrics (runtime, memory)\n",
                "- \u26a0\ufe0f Requires LeetCode account\n",
                "- \u26a0\ufe0f Rate limited (15s cooldown between submissions)\n",
                "\n",
                "### Step-by-Step Setup\n",
                "\n",
                "#### Step 1: Log into LeetCode\n",
                "\n",
                "1. Open your browser and go to [leetcode.com](https://leetcode.com)\n",
                "2. Log into your account\n",
                "\n",
                "#### Step 2: Get the Session Cookie\n",
                "\n",
                "**For Chrome/Edge:**\n",
                "1. Right-click anywhere on LeetCode \u2192 \"Inspect\" (or press F12)\n",
                "2. Go to **Application** tab \u2192 **Cookies** \u2192 `https://leetcode.com`\n",
                "3. Find the cookie named `LEETCODE_SESSION`\n",
                "4. Copy its **Value** (it's a long string starting with `eyJ...`)\n",
                "\n",
                "**For Firefox:**\n",
                "1. Right-click \u2192 \"Inspect Element\" \u2192 **Storage** tab \u2192 **Cookies**\n",
                "2. Find `LEETCODE_SESSION` and copy its value\n",
                "\n",
                "#### Step 3: Set Environment Variable\n",
                "\n",
                "```bash\n",
                "# In terminal (temporary, for current session)\n",
                "export LEETCODE_SESSION='eyJ...your_long_session_value...'\n",
                "\n",
                "# Or add to ~/.bashrc or ~/.zshrc (permanent)\n",
                "echo 'export LEETCODE_SESSION=\"eyJ...\"' >> ~/.zshrc\n",
                "source ~/.zshrc\n",
                "```\n",
                "\n",
                "#### Step 4: Verify Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check if LEETCODE_SESSION is set\n",
                "from domains.code_debugging.utils import check_leetcode_session\n",
                "\n",
                "print(\"\ud83d\udd10 LeetCode Session Check\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "if check_leetcode_session():\n",
                "    session = os.environ.get('LEETCODE_SESSION', '')\n",
                "    print(\"\u2705 LEETCODE_SESSION is set!\")\n",
                "    print(f\"   Value preview: {session[:20]}...{session[-20:]}\")\n",
                "    print(\"\\n   LeetCode validation will work.\")\n",
                "else:\n",
                "    print(\"\u274c LEETCODE_SESSION is NOT set!\")\n",
                "    print(\"\\n   To set it, run in your terminal:\")\n",
                "    print(\"   export LEETCODE_SESSION='your_session_cookie_value'\")\n",
                "    print(\"\\n   Or set it here for this notebook session:\")\n",
                "    print(\"   (uncomment and fill in the next cell)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# OPTIONAL: Set the session cookie here (for this notebook only)\n",
                "# \u26a0\ufe0f WARNING: Do not commit this value to git!\n",
                "\n",
                "# Uncomment and fill in your session cookie:\n",
                "# os.environ['LEETCODE_SESSION'] = 'eyJ...your_session_value_here...'\n",
                "\n",
                "# Then re-run the check:\n",
                "# print(\"Session set!\" if check_leetcode_session() else \"Failed to set session\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Important Notes About LeetCode Validation\n",
                "\n",
                "| Aspect | Details |\n",
                "|--------|--------|\n",
                "| **Rate Limiting** | 15-second cooldown between submissions (enforced by code) |\n",
                "| **Session Expiry** | Cookies expire. If validation fails, get a new session cookie. |\n",
                "| **Account Risk** | Using automated submissions may violate LeetCode ToS. Use responsibly. |\n",
                "| **Without Session** | Domain can still load problems and parse solutions, but cannot validate. |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Part 4: Domain Architecture Deep Dive\n",
                "\n",
                "### File Structure\n",
                "\n",
                "```\n",
                "domains/code_debugging/\n",
                "\u251c\u2500\u2500 code_debugging_domain.py    # Main DomainInterface implementation\n",
                "\u251c\u2500\u2500 data_loader.py              # Load problems from DebugBench JSON\n",
                "\u251c\u2500\u2500 validator.py                # LeetCode API wrapper\n",
                "\u251c\u2500\u2500 leetcode_tester.py          # LeetCodeTester class\n",
                "\u251c\u2500\u2500 leetcode_env/               # LeetCode environment (from DebugBench)\n",
                "\u251c\u2500\u2500 prompt_builder.py           # IO_INTENTION_PROMPT construction\n",
                "\u251c\u2500\u2500 solution_parser.py          # Extract <code></code> tags\n",
                "\u251c\u2500\u2500 utils.py                    # Helper functions\n",
                "\u2514\u2500\u2500 data/                       # DebugBench JSON files\n",
                "```\n",
                "\n",
                "### 4.1 The Data Loader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\ud83d\udcc2 Data Loader\")\n",
                "print(\"=\" * 60)\n",
                "print(\"\"\"\n",
                "load_problem_from_dataset(\n",
                "    language='Python3',        # Only Python3 supported\n",
                "    bug_type=None,             # Specific type or None for random\n",
                "    problem_index=None         # Specific index or None for random\n",
                ") -> CodeDebuggingProblem\n",
                "\n",
                "Loads problems from domains/code_debugging/data/python3_*.json\n",
                "\"\"\")\n",
                "\n",
                "# Demo: Load random problem\n",
                "random_problem = load_problem_from_dataset()\n",
                "print(f\"\\nRandom problem loaded:\")\n",
                "print(f\"  Slug: {random_problem.slug}\")\n",
                "print(f\"  Bug type: {random_problem.bug_type}\")\n",
                "print(f\"  Level: {random_problem.level}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.2 The Prompt Builder (IO_INTENTION_PROMPT)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from domains.code_debugging.prompt_builder import build_debugging_prompt, IO_INTENTION_PROMPT_TEMPLATE\n",
                "\n",
                "print(\"\ud83d\udcdd Prompt Builder (IO_INTENTION_PROMPT)\")\n",
                "print(\"=\" * 60)\n",
                "print(\"\\nTemplate structure:\")\n",
                "print(\"-\" * 60)\n",
                "print(IO_INTENTION_PROMPT_TEMPLATE[:500] + \"...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate a full prompt\n",
                "print(\"\\n\ud83d\udcdc Generated Prompt Example\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "prompt = build_debugging_prompt(problem, episodic_examples=None)\n",
                "print(prompt[:1500] + \"...\" if len(prompt) > 1500 else prompt)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Key Points About the Prompt:\n",
                "\n",
                "1. **Structured Format**: Uses `{LANG}`, `{DESCRIPTION}`, `{EXAMPLES}`, `{CONSTRAINTS}`, `{BUGGY_CODE}`\n",
                "\n",
                "2. **Expected Output**: LLM must respond with:\n",
                "   ```\n",
                "   <code>\n",
                "   fixed code here\n",
                "   </code>\n",
                "   <exp>\n",
                "   short explanation about the bug\n",
                "   </exp>\n",
                "   ```\n",
                "\n",
                "3. **Episodic Examples**: Can include past problem-solution pairs for few-shot learning"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.3 The Solution Parser"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from domains.code_debugging.solution_parser import parse_fixed_code, parse_explanation\n",
                "\n",
                "print(\"\ud83d\udd0d Solution Parser\")\n",
                "print(\"=\" * 60)\n",
                "print(\"\"\"\n",
                "Extracts fixed code from LLM response.\n",
                "\n",
                "Priority:\n",
                "1. <code>...</code> tags (preferred)\n",
                "2. ```python...``` markdown blocks\n",
                "3. ```...``` generic code blocks\n",
                "4. Entire response (fallback)\n",
                "\"\"\")\n",
                "\n",
                "# Test parsing\n",
                "test_responses = [\n",
                "    # Correct format\n",
                "    \"\"\"<code>\n",
                "class Solution:\n",
                "    def twoSum(self, nums, target):\n",
                "        for i in range(len(nums)):\n",
                "            for j in range(i+1, len(nums)):\n",
                "                if nums[i] + nums[j] == target:\n",
                "                    return [i, j]\n",
                "</code>\n",
                "<exp>\n",
                "Fixed the loop range to avoid index out of bounds\n",
                "</exp>\"\"\",\n",
                "    \n",
                "    # Markdown format\n",
                "    \"\"\"Here is the fixed code:\n",
                "```python\n",
                "def solution():\n",
                "    return True\n",
                "```\"\"\",\n",
                "]\n",
                "\n",
                "for i, response in enumerate(test_responses, 1):\n",
                "    code = parse_fixed_code(response)\n",
                "    exp = parse_explanation(response)\n",
                "    print(f\"\\nResponse {i}:\")\n",
                "    print(f\"  Extracted code ({len(code)} chars): {code[:50]}...\")\n",
                "    print(f\"  Explanation: {exp if exp else 'None found'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.4 The LeetCode Validator"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\u2705 LeetCode Validator\")\n",
                "print(\"=\" * 60)\n",
                "print(\"\"\"\n",
                "validate_code_with_leetcode(\n",
                "    code: str,           # The Python code to submit\n",
                "    task_id: str,        # LeetCode problem slug (e.g., 'two-sum')\n",
                "    language: str        # 'Python3'\n",
                ") -> Tuple[bool, Dict]\n",
                "\n",
                "Returns:\n",
                "  - (True, {status_msg: 'Accepted', runtime, memory})\n",
                "  - (False, {status_msg, error, last_testcase, expected, actual})\n",
                "\n",
                "Features:\n",
                "  \u2022 15-second cooldown between submissions (prevents rate limiting)\n",
                "  \u2022 Singleton pattern (reuses LeetCodeTester instance)\n",
                "  \u2022 Handles environment errors gracefully\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Demonstrate validation (without actually submitting)\n",
                "print(\"\\n\ud83d\udccb Validation Flow\")\n",
                "print(\"-\" * 60)\n",
                "print(\"\"\"\n",
                "1. Check LEETCODE_SESSION environment variable\n",
                "2. Create LeetCodeTester (singleton)\n",
                "3. Wait for cooldown if needed (15s)\n",
                "4. Submit code to LeetCode API\n",
                "5. Wait for results\n",
                "6. Return (is_valid, feedback)\n",
                "\"\"\")\n",
                "\n",
                "# Show what feedback looks like\n",
                "print(\"\\n\ud83d\udcca Example Feedback (Success):\")\n",
                "print({\n",
                "    'status_msg': 'Accepted',\n",
                "    'runtime': '40 ms',\n",
                "    'memory': '14.2 MB',\n",
                "    'status_runtime': 'beats 95%'\n",
                "})\n",
                "\n",
                "print(\"\\n\ud83d\udcca Example Feedback (Failure):\")\n",
                "print({\n",
                "    'status_msg': 'Wrong Answer',\n",
                "    'last_testcase': 'nums = [2,7,11,15], target = 9',\n",
                "    'expected_output': '[0, 1]',\n",
                "    'code_output': '[1, 0]'\n",
                "})"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Part 5: The Complete Domain Implementation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from domains.code_debugging.code_debugging_domain import CodeDebuggingDomain\n",
                "\n",
                "print(\"\ud83c\udfae Complete Domain Workflow (Without LLM)\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "# Step 1: Create domain\n",
                "domain = CodeDebuggingDomain()\n",
                "print(\"\\n1\ufe0f\u20e3 Created CodeDebuggingDomain\")\n",
                "\n",
                "# Step 2: Generate a problem\n",
                "problem = domain.generate_problem(bug_type=\"condition error\")\n",
                "print(f\"\\n2\ufe0f\u20e3 Generated Problem:\")\n",
                "print(f\"   Slug: {problem.slug}\")\n",
                "print(f\"   Bug Type: {problem.bug_type}\")\n",
                "print(f\"   Level: {problem.level}\")\n",
                "\n",
                "# Step 3: Build prompt\n",
                "prompt = domain.build_prompt(problem, episodic_examples=None)\n",
                "print(f\"\\n3\ufe0f\u20e3 Built Prompt ({len(prompt)} chars)\")\n",
                "\n",
                "# Step 4: Simulate LLM response (use oracle code)\n",
                "simulated_response = f\"<code>\\n{problem.oracle_code}\\n</code>\\n<exp>Fixed the condition error</exp>\"\n",
                "print(f\"\\n4\ufe0f\u20e3 Simulated LLM Response (using oracle code)\")\n",
                "\n",
                "# Step 5: Parse solution\n",
                "solution = domain.parse_solution(simulated_response)\n",
                "print(f\"\\n5\ufe0f\u20e3 Parsed Solution ({len(solution)} chars)\")\n",
                "print(f\"   First 100 chars: {solution[:100]}...\")\n",
                "\n",
                "# Step 6: Memory representation\n",
                "prob_repr = domain.get_problem_representation(problem)\n",
                "sol_repr = domain.format_solution_for_memory(solution)\n",
                "print(f\"\\n6\ufe0f\u20e3 Memory Representations:\")\n",
                "print(f\"   Problem: {prob_repr[:80]}...\")\n",
                "print(f\"   Solution: {sol_repr[:80]}...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test validation (only if LEETCODE_SESSION is set)\n",
                "print(\"\\n7\ufe0f\u20e3 Validation Step\")\n",
                "print(\"-\" * 60)\n",
                "\n",
                "if check_leetcode_session():\n",
                "    print(\"\u26a0\ufe0f LeetCode session is set.\")\n",
                "    print(\"   To actually validate, uncomment the code below.\")\n",
                "    print(\"   WARNING: This will submit to LeetCode and count toward rate limits!\")\n",
                "    \n",
                "    # Uncomment to actually validate:\n",
                "    # is_valid, feedback = domain.validate_solution(problem, solution)\n",
                "    # print(f\"   Valid: {is_valid}\")\n",
                "    # print(f\"   Feedback: {domain.format_feedback(feedback)}\")\n",
                "else:\n",
                "    print(\"\u274c LEETCODE_SESSION not set - skipping validation\")\n",
                "    print(\"   Set the environment variable to enable real validation.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Part 6: Running with the Full SOFAI Framework \ud83d\ude80\n",
                "\n",
                "**Requirements:**\n",
                "- Ollama running with a model\n",
                "- LEETCODE_SESSION set (for validation)\n",
                "\n",
                "Without LeetCode session, the domain will run but validation will fail."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# system deps\n",
                "!sudo apt-get update\n",
                "!sudo apt-get install -y zstd\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install Ollama\n",
                "!curl https://ollama.ai/install.sh | sh\n",
                "!pip install -q ollama\n",
                "\n",
                "!nvidia-smi\n",
                "!ollama serve > /tmp/ollama.log 2>&1 &\n",
                "!sleep 2\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check Ollama availability and ensure model is pulled\n",
                "import subprocess\n",
                "\n",
                "MODEL_NAME = 'mistral'  # Change this to use a different model\n",
                "\n",
                "def check_ollama():\n",
                "    try:\n",
                "        result = subprocess.run(['ollama', 'list'], capture_output=True, text=True, timeout=5)\n",
                "        if result.returncode == 0:\n",
                "            print(\"\u2705 Ollama is available!\")\n",
                "            return True\n",
                "    except:\n",
                "        pass\n",
                "    print(\"\u274c Ollama not available\")\n",
                "    return False\n",
                "\n",
                "def ensure_model_available(model_name):\n",
                "    \"\"\"Check if model exists, pull if not.\"\"\"\n",
                "    try:\n",
                "        result = subprocess.run(['ollama', 'list'], capture_output=True, text=True, timeout=10)\n",
                "        if model_name in result.stdout:\n",
                "            print(f\"\u2705 Model '{model_name}' is available.\")\n",
                "            return True\n",
                "        \n",
                "        print(f\"\u2b07\ufe0f Model '{model_name}' not found. Pulling...\")\n",
                "        pull_result = subprocess.run(['ollama', 'pull', model_name], timeout=600)\n",
                "        if pull_result.returncode == 0:\n",
                "            print(f\"\u2705 Model '{model_name}' pulled successfully.\")\n",
                "            return True\n",
                "    except Exception as e:\n",
                "        print(f\"\u274c Error: {e}\")\n",
                "    return False\n",
                "\n",
                "ollama_available = check_ollama()\n",
                "if ollama_available:\n",
                "    ensure_model_available(MODEL_NAME)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if ollama_available:\n",
                "    from core.metacognitive_module import MCModule\n",
                "    \n",
                "    print(\"=\" * 60)\n",
                "    print(\"\ud83d\udc1b Running SOFAI with Code Debugging Domain\")\n",
                "    print(\"=\" * 60)\n",
                "    \n",
                "    # Create domain and problem\n",
                "    domain = CodeDebuggingDomain()\n",
                "    problem = domain.generate_problem(bug_type=\"missing colons\")  # Easier bug type\n",
                "    \n",
                "    print(f\"\\n\ud83d\udcca Problem: {problem.slug}\")\n",
                "    print(f\"   Bug Type: {problem.bug_type}\")\n",
                "    print(f\"   Level: {problem.level}\")\n",
                "    print(f\"\\n\ud83d\udc1b Buggy Code Preview:\")\n",
                "    print(problem.buggy_code[:300] + \"...\")\n",
                "    \n",
                "    # Create MCModule\n",
                "    mc = MCModule(\n",
                "        domain=domain,\n",
                "        llm_model=\"mistral\",\n",
                "        max_iterations=2  # Fewer iterations due to LeetCode rate limits\n",
                "    )\n",
                "    \n",
                "    print(\"\\n\u23f3 Starting solve process...\")\n",
                "    print(\"   (Note: Each iteration may take 15+ seconds due to LeetCode cooldown)\")\n",
                "    \n",
                "    # Solve!\n",
                "    result = mc.solve(problem, verbose=True)\n",
                "    \n",
                "    # Display results\n",
                "    print(\"\\n\" + \"=\" * 60)\n",
                "    print(\"\ud83d\udccb Final Results\")\n",
                "    print(\"=\" * 60)\n",
                "    print(f\"Solved: {result['solved']}\")\n",
                "    print(f\"Solved by: {'S1' if result['s1_solved'] else 'S2' if result['s2_solved'] else 'None'}\")\n",
                "    print(f\"Iterations: {result['iterations']}\")\n",
                "    print(f\"Total time: {result['total_time']:.2f}s\")\n",
                "    if result['solution']:\n",
                "        print(f\"\\n\u2705 Fixed Code Preview:\")\n",
                "        print(result['solution'][:300] + \"...\")\n",
                "else:\n",
                "    print(\"\\n\u26a0\ufe0f Skipping live demo - Ollama not available\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Part 7: Understanding the Feedback Loop\n",
                "\n",
                "When validation fails, the domain provides detailed feedback to help the LLM correct its solution."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Demonstrate feedback formatting\n",
                "print(\"\ud83d\udd04 Feedback Examples\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "domain = CodeDebuggingDomain()\n",
                "\n",
                "# Example 1: Accepted\n",
                "feedback1 = {'status_msg': 'Accepted', 'runtime': '40 ms', 'memory': '14.2 MB'}\n",
                "print(f\"\\n\u2705 Success Feedback:\")\n",
                "print(f\"   {domain.format_feedback(feedback1)}\")\n",
                "\n",
                "# Example 2: Wrong Answer\n",
                "feedback2 = {\n",
                "    'status_msg': 'Wrong Answer',\n",
                "    'last_testcase': 'nums = [2,7,11,15], target = 9',\n",
                "    'expected_output': '[0, 1]',\n",
                "    'code_output': '[1, 0]'\n",
                "}\n",
                "print(f\"\\n\u274c Wrong Answer Feedback:\")\n",
                "print(f\"   {domain.format_feedback(feedback2)}\")\n",
                "\n",
                "# Example 3: Runtime Error\n",
                "feedback3 = {\n",
                "    'status_msg': 'Runtime Error',\n",
                "    'full_runtime_error': 'IndexError: list index out of range'\n",
                "}\n",
                "print(f\"\\n\u274c Runtime Error Feedback:\")\n",
                "print(f\"   {domain.format_feedback(feedback3)}\")\n",
                "\n",
                "# Example 4: Compile Error\n",
                "feedback4 = {\n",
                "    'status_msg': 'Compile Error',\n",
                "    'compile_error': 'SyntaxError: invalid syntax at line 5'\n",
                "}\n",
                "print(f\"\\n\u274c Compile Error Feedback:\")\n",
                "print(f\"   {domain.format_feedback(feedback4)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Part 8: Best Practices & Troubleshooting\n",
                "\n",
                "### Common Issues\n",
                "\n",
                "| Issue | Solution |\n",
                "|-------|----------|\n",
                "| `EnvironmentError: LEETCODE_SESSION not set` | Set the environment variable (see Part 3) |\n",
                "| `Session expired` | Get a new session cookie from LeetCode |\n",
                "| `Rate limited` | Wait longer between submissions (cooldown is 15s) |\n",
                "| `Timeout` | LeetCode API may be slow; increase timeout |\n",
                "| `404 error on problem` | Problem slug might be wrong in dataset |\n",
                "\n",
                "### Tips for Better Results\n",
                "\n",
                "1. **Start with syntax bugs** (missing colons, indentation) - easier for LLMs\n",
                "2. **Use fewer iterations** to avoid rate limiting\n",
                "3. **Consider S2 with stronger model** for logic bugs\n",
                "4. **Monitor LeetCode daily submission limits**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Summary: Key Takeaways \ud83c\udfaf\n",
                "\n",
                "1. **Code Debugging as CSP**: Fix buggy code to pass all test cases\n",
                "\n",
                "2. **DebugBench Dataset**: 4,253+ Python3 problems across 17 bug types\n",
                "\n",
                "3. **LeetCode Validation**: Real test execution for accurate feedback\n",
                "   - Requires `LEETCODE_SESSION` environment variable\n",
                "   - 15-second cooldown between submissions\n",
                "\n",
                "4. **IO_INTENTION_PROMPT**: Structured format for LLM debugging\n",
                "   - Expects `<code>...</code>` and `<exp>...</exp>` tags\n",
                "\n",
                "5. **Feedback Loop**: Detailed error messages help LLM iterate\n",
                "\n",
                "6. **Challenges**: Rate limiting, session expiry, complex logic bugs\n",
                "\n",
                "---\n",
                "\n",
                "## Next Steps\n",
                "\n",
                "- Review the Graph Coloring notebook for comparison\n",
                "- Try creating a custom domain using the templates\n",
                "- Experiment with different LLM models for code debugging\n",
                "\n",
                "Happy debugging! \ud83d\udc1b\ud83d\udd27"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}